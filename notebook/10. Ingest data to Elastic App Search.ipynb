{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "realistic-harbor",
   "metadata": {},
   "source": [
    "# Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fatal-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import analyzer, Document, Date, Text, Integer, Keyword, Double\n",
    "from elastic_enterprise_search import AppSearch\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mechanical-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elastic App Search\n",
    "app_search = AppSearch(\n",
    "    \"http://localhost:3002\",\n",
    "    http_auth=\"private-6jj3ai4ckkq2xykcocosmv6o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "representative-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a document class using data types from elasticsearch_dsl\n",
    "class Listing(Document):\n",
    "    id = Text()\n",
    "    org_id = Integer()\n",
    "    listing_url = Text()\n",
    "    scrape_id = Integer()\n",
    "    last_scraped = Keyword()\n",
    "    crawled_date = Date()\n",
    "    name = Text(analyzer='snowball')\n",
    "    host_id = Integer()\n",
    "    host_is_superhost = Keyword()\n",
    "    host_identity_verified = Text(fields={'raw': Keyword()})\n",
    "    room_type = Text(fields={'raw': Keyword()})\n",
    "    accommodates = Integer()\n",
    "    guests_included = Integer()\n",
    "    minimum_nights = Integer()\n",
    "    maximum_nights = Integer()\n",
    "    calendar_updated = Text(fields={'raw': Keyword()})\n",
    "    instant_bookable = Keyword()\n",
    "    is_business_travel_ready = Keyword()\n",
    "    cancellation_policy = Text(fields={'raw': Keyword()})\n",
    "    price = Integer()\n",
    "    availability_30 = Integer()\n",
    "    availability_60 = Integer()\n",
    "    availability_90 = Integer()\n",
    "    availability_365 = Integer()\n",
    "    number_of_reviews = Integer()\n",
    "    first_review = Text(fields={'raw': Keyword()})\n",
    "    last_review = Text(fields={'raw': Keyword()})\n",
    "    review_scores_rating = Integer()\n",
    "    review_scores_accuracy = Integer()\n",
    "    review_scores_cleanliness = Integer()\n",
    "    review_scores_checkin = Integer()\n",
    "    review_scores_communication = Integer()\n",
    "    review_scores_location = Integer()\n",
    "    review_scores_value = Integer()\n",
    "    overall_rating = Double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elegant-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for processing documents\n",
    "def clean_currency(price):\n",
    "    \n",
    "    if '$' in price:\n",
    "        price = price.replace('$', '')\n",
    "\n",
    "    if ',' in price:\n",
    "        price = price.replace(',', '')\n",
    "\n",
    "    return price\n",
    "\n",
    "def get_overall_rating(row):\n",
    "    \"\"\" Get overall rating using review fields as target indicator \"\"\"\n",
    "    \n",
    "    review_scores_accuracy = float(row['review_scores_accuracy'])\n",
    "    review_scores_cleanliness = float(row['review_scores_cleanliness'])\n",
    "    review_scores_checkin = float(row['review_scores_checkin'])\n",
    "    review_scores_communication = float(row['review_scores_communication'])\n",
    "    review_scores_location = float(row['review_scores_location'])\n",
    "    review_scores_value = float(row['review_scores_value'])\n",
    "\n",
    "    overall_rating = (((review_scores_accuracy + review_scores_cleanliness \\\n",
    "                      + review_scores_checkin + review_scores_communication \\\n",
    "                      + review_scores_location + review_scores_value) / 2.0) / 6.0)\n",
    "    return overall_rating\n",
    "\n",
    "def validate_price(df):\n",
    "    \"\"\" Validate price (if exists), otherwise assign default a value\"\"\"\n",
    "    \n",
    "    # Convert 'price' to float\n",
    "    if('price' in df.columns):\n",
    "        \n",
    "        # Fill rows with null 'price'\n",
    "        df['price'].fillna(value='0', inplace=True)\n",
    "\n",
    "        df['price'] = df['price'].apply(clean_currency).astype('float')\n",
    "\n",
    "    # Handle data with no 'price', e.g., athens_2020-07-21_data_listings.csv.gz\n",
    "    elif ('price' not in df.columns):\n",
    "        \n",
    "        if ('weekly_price' in df.columns):\n",
    "\n",
    "            # Fill rows with null 'weekly_price'\n",
    "            df['weekly_price'].fillna(value='0', inplace=True)\n",
    "            \n",
    "            df['weekly_price'] = df['weekly_price'].apply(clean_currency).astype('float')\n",
    "            df['price'] = df['weekly_price'] / 7.0\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Set missigng 'price' and 'weekly_price' to 0\n",
    "            df['price'].fillna(value='0', inplace=True)\n",
    "            df['weekly_price'].fillna(value='0', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_crawled_date(df):\n",
    "    \"\"\" Extract crawled date from the 'scrape_id' field. \"\"\"\n",
    "\n",
    "    df['crawled_date'] = df['scrape_id'].astype(str)\n",
    "    df['crawled_date'] = df['crawled_date'].apply(lambda x: x[:8])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def gen_missing_columns(df):\n",
    "    \"\"\" Extract 'guests_included' from the 'accommodates' field. \"\"\"\n",
    "\n",
    "    if 'host_is_superhost' not in df.columns:\n",
    "        df['host_is_superhost'] = \"f\"\n",
    "\n",
    "    if 'host_identity_verified' not in df.columns:\n",
    "        df['host_identity_verified'] = \"f\"\n",
    "\n",
    "    if 'room_type' not in df.columns:\n",
    "        df['room_type'] = \"n/a\"\n",
    "\n",
    "    if 'accommodates' not in df.columns:\n",
    "        df['accommodates'] = 0\n",
    "\n",
    "    if 'guests_included' not in df.columns:\n",
    "        df['guests_included'] = df['accommodates']\n",
    "\n",
    "    if 'minimum_nights' not in df.columns:\n",
    "        df['minimum_nights'] = 0\n",
    "\n",
    "    if 'maximum_nights' not in df.columns:\n",
    "        df['maximum_nights'] = 0\n",
    "\n",
    "    if 'calendar_updated' not in df.columns:\n",
    "        df['calendar_updated'] = \"n/a\"\n",
    "\n",
    "    if 'instant_bookable' not in df.columns:\n",
    "        df['instant_bookable'] = \"f\"\n",
    "\n",
    "    if 'is_business_travel_ready' not in df.columns:\n",
    "        df['is_business_travel_ready'] = \"f\"\n",
    "\n",
    "    if 'cancellation_policy' not in df.columns:\n",
    "        df['cancellation_policy'] = \"n/a\"\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_features(df):\n",
    "    \"\"\" Select specific columns and convert date columnd to string. \"\"\"\n",
    "    \n",
    "    df = df[\n",
    "            [ \n",
    "                'id', 'listing_url', 'scrape_id', 'last_scraped', 'crawled_date', \n",
    "                'name', 'host_id', 'host_is_superhost', 'host_identity_verified', \n",
    "                'room_type', 'accommodates', 'guests_included','minimum_nights', \n",
    "                'maximum_nights', 'calendar_updated', 'instant_bookable', 'is_business_travel_ready', 'cancellation_policy',\n",
    "                'price', 'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "                'number_of_reviews', 'first_review', 'last_review', 'review_scores_rating', \n",
    "                'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', \n",
    "                'review_scores_communication', 'review_scores_location', 'review_scores_value'\n",
    "            ]\n",
    "    ]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def validate_reviews(df):\n",
    "    \"\"\" Enrich no review records with default review scores. \"\"\"\n",
    "    \n",
    "    df['first_review'].fillna(value='1991-01-01', inplace=True)\n",
    "    df['last_review'].fillna(value='0', inplace=True)\n",
    "    df['review_scores_rating'].fillna(value=0, inplace=True)\n",
    "    df['review_scores_accuracy'].fillna(value=0, inplace=True)\n",
    "    df['review_scores_accuracy'].fillna(value=0, inplace=True)\n",
    "    df['review_scores_cleanliness'].fillna(value=0, inplace=True)\n",
    "    df['review_scores_checkin'].fillna(value=0, inplace=True)\n",
    "    df['review_scores_communication'].fillna(value=0, inplace=True)\n",
    "    df['review_scores_location'].fillna(value=0, inplace=True)\n",
    "    df['review_scores_value'].fillna(value=0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_null_values(df):\n",
    "    \"\"\" Drop records with NaN values. \"\"\"\n",
    "    \n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "def fill_null_values(df):\n",
    "    \"\"\" Fill records with NaN values. \"\"\"\n",
    "    \n",
    "    df['listing_url'].fillna(value=' ', inplace=True)\n",
    "    df['scrape_id'].fillna(value=0, inplace=True)\n",
    "    df['last_scraped'].fillna(value='1991-01-01', inplace=True)\n",
    "    df['crawled_date'].fillna(value='1991-01-01', inplace=True)\n",
    "    df['name'].fillna(value=' ', inplace=True)\n",
    "    df['host_id'].fillna(value=0, inplace=True)\n",
    "    df['host_is_superhost'].fillna(value=' ', inplace=True)\n",
    "    df['host_identity_verified'].fillna(value=' ', inplace=True)\n",
    "    df['room_type'].fillna(value=' ', inplace=True)\n",
    "    df['accommodates'].fillna(value=0, inplace=True)\n",
    "    df['guests_included'].fillna(value=0, inplace=True)\n",
    "    df['minimum_nights'].fillna(value=0, inplace=True)\n",
    "    df['maximum_nights'].fillna(value=0, inplace=True)\n",
    "    df['calendar_updated'].fillna(value=' ', inplace=True)\n",
    "    df['instant_bookable'].fillna(value=' ', inplace=True)\n",
    "    df['is_business_travel_ready'].fillna(value=' ', inplace=True)\n",
    "    df['cancellation_policy'].fillna(value=' ', inplace=True)\n",
    "    df['price'].fillna(value=0, inplace=True)\n",
    "    df['availability_30'].fillna(value=0, inplace=True)\n",
    "    df['availability_60'].fillna(value=0, inplace=True)\n",
    "    df['availability_90'].fillna(value=0, inplace=True)\n",
    "    df['availability_365'].fillna(value=0, inplace=True)\n",
    "    df['number_of_reviews'].fillna(value=0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ruled-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for indexing documents\n",
    "def ingest_data(df, index, total_docs):\n",
    "    \"\"\" Finalize data and ingest a bulk of documents to ES index \"\"\"\n",
    "\n",
    "    try:\n",
    "        i = 0\n",
    "        bulk_size = 100\n",
    "        docs = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            \n",
    "            # Count the number of documents\n",
    "            i += 1\n",
    "            \n",
    "            doc = Listing()\n",
    "            \n",
    "            if ('id' in row) and ('crawled_date' in row):\n",
    "                org_id = row['id']\n",
    "                crawled_date = row['crawled_date']\n",
    "                \n",
    "                # Generate an unique ID by concating the orignal ID with crawled date\n",
    "                doc.id = str(org_id) + \"-\" + crawled_date\n",
    "                \n",
    "                doc.org_id = org_id\n",
    "                doc.crawled_date = crawled_date\n",
    "            if 'listing_url' in row:\n",
    "                doc.listing_url = row['listing_url']\n",
    "            if 'scrape_id' in row:\n",
    "                doc.scrape_id = row['scrape_id']\n",
    "            if 'last_scraped' in row:\n",
    "                doc.last_scraped = str(row['last_scraped']).replace(\"-\", \"\")\n",
    "            if 'name' in row:\n",
    "                doc.name = row['name']\n",
    "            if 'host_id' in row:\n",
    "                doc.host_id = row['host_id']\n",
    "            if 'host_is_superhost' in row:\n",
    "                doc.host_is_superhost = row['host_is_superhost']\n",
    "            if 'host_identity_verified'in row:\n",
    "                doc.host_identity_verified = row['host_identity_verified']\n",
    "            if 'room_type' in row:\n",
    "                doc.room_type = row['room_type']\n",
    "            if 'accommodates' in row:\n",
    "                doc.accommodates = row['accommodates']\n",
    "            if 'guests_included' in row:\n",
    "                doc.guests_included = row['guests_included']\n",
    "            if 'minimum_nights' in row:\n",
    "                doc.minimum_nights = row['minimum_nights']\n",
    "            if 'maximum_nights' in row:\n",
    "                doc.maximum_nights = row['maximum_nights']\n",
    "            if 'calendar_updated' in row:\n",
    "                doc.calendar_updated = row['calendar_updated']\n",
    "            if 'instant_bookable' in row:\n",
    "                doc.instant_bookable = row['instant_bookable']\n",
    "            if 'is_business_travel_ready' in row:\n",
    "                doc.is_business_travel_ready = row['is_business_travel_ready']\n",
    "            if 'cancellation_policy' in row:\n",
    "                doc.cancellation_policy = row['cancellation_policy']\n",
    "            if 'price' in row:\n",
    "                doc.price = row['price']\n",
    "            if 'availability_30' in row:\n",
    "                doc.availability_30 = row['availability_30']\n",
    "            if 'availability_60' in row:\n",
    "                doc.availability_60 = row['availability_60']\n",
    "            if 'availability_90' in row:\n",
    "                doc.availability_90 = row['availability_90']\n",
    "            if 'availability_365' in row:\n",
    "                doc.availability_365 = row['availability_365']\n",
    "            if 'number_of_reviews' in row:\n",
    "                doc.number_of_reviews = row['number_of_reviews']\n",
    "            if 'first_review' in row:\n",
    "                doc.first_review = str(row['first_review']).replace(\"-\", \"\")\n",
    "            if 'last_review' in row:\n",
    "                doc.last_review = str(row['last_review']).replace(\"-\", \"\")\n",
    "            if 'review_scores_rating' in row:\n",
    "                doc.review_scores_rating = row['review_scores_rating']\n",
    "            if 'review_scores_accuracy' in row:\n",
    "                doc.review_scores_accuracy = row['review_scores_accuracy']\n",
    "            if 'review_scores_cleanliness' in row:\n",
    "                doc.review_scores_cleanliness = row['review_scores_cleanliness']\n",
    "            if 'review_scores_checkin' in row:\n",
    "                doc.review_scores_checkin = row['review_scores_checkin']\n",
    "            if 'review_scores_communication' in row:\n",
    "                doc.review_scores_communication = row['review_scores_communication']\n",
    "            if 'review_scores_location' in row:\n",
    "                doc.review_scores_location = row['review_scores_location']\n",
    "            if 'review_scores_value' in row:\n",
    "                doc.review_scores_value = row['review_scores_value']\n",
    "          \n",
    "            # Compute overall_rating by averaging all reviews scores\n",
    "            overall_rating = get_overall_rating(row)\n",
    "            doc.overall_rating = overall_rating\n",
    "\n",
    "            # Append the current document to a list of documents\n",
    "            docs.append(doc.to_dict(include_meta=False))\n",
    "            \n",
    "            # Ingest a bulk of documents into the current index\n",
    "            if ((i % bulk_size) == 0) or (i == total_docs):\n",
    "                app_search.index_documents(\n",
    "                    engine_name=index,\n",
    "                    documents=docs\n",
    "                )\n",
    "                \n",
    "                # Reset the list of documents\n",
    "                docs = []\n",
    "            \n",
    "    except Exception:\n",
    "        logging.error('exception occured', exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "neither-retail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start indexing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (43,61,62) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating a new index with 18033 documents loaded from file: barcelona_2019-01-14_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (61,62) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 17763 documents loaded from file: barcelona_2019-02-06_data_listings.csv.gz\n",
      "\tUpdating an existing index with 17807 documents loaded from file: barcelona_2019-03-08_data_listings.csv.gz\n",
      "\tUpdating an existing index with 17899 documents loaded from file: barcelona_2019-04-10_data_listings.csv.gz\n",
      "\tUpdating an existing index with 18302 documents loaded from file: barcelona_2019-05-14_data_listings.csv.gz\n",
      "\tUpdating an existing index with 18837 documents loaded from file: barcelona_2019-06-07_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19833 documents loaded from file: barcelona_2019-07-10_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20556 documents loaded from file: barcelona_2019-08-12_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20404 documents loaded from file: barcelona_2019-09-17_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20147 documents loaded from file: barcelona_2019-10-16_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20428 documents loaded from file: barcelona_2019-11-09_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20843 documents loaded from file: barcelona_2019-12-10_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20708 documents loaded from file: barcelona_2020-01-10_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20981 documents loaded from file: barcelona_2020-02-16_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21116 documents loaded from file: barcelona_2020-03-16_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20838 documents loaded from file: barcelona_2020-04-16_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20858 documents loaded from file: barcelona_2020-05-11_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20864 documents loaded from file: barcelona_2020-06-13_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20517 documents loaded from file: barcelona_2020-07-17_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20703 documents loaded from file: barcelona_2020-08-24_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20337 documents loaded from file: barcelona_2020-09-12_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19896 documents loaded from file: barcelona_2020-10-12_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19896 documents loaded from file: barcelona_2020-11-06_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19641 documents loaded from file: barcelona_2020-12-16_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (61,62,95) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating a new index with 18222 documents loaded from file: buenos-aires_2019-03-15_data_listings.csv.gz\n",
      "\tUpdating an existing index with 18708 documents loaded from file: buenos-aires_2019-04-17_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20715 documents loaded from file: buenos-aires_2019-07-16_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21228 documents loaded from file: buenos-aires_2019-08-27_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21646 documents loaded from file: buenos-aires_2019-09-24_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21968 documents loaded from file: buenos-aires_2019-10-20_data_listings.csv.gz\n",
      "\tUpdating an existing index with 22877 documents loaded from file: buenos-aires_2019-11-25_data_listings.csv.gz\n",
      "\tUpdating an existing index with 23605 documents loaded from file: buenos-aires_2019-12-27_data_listings.csv.gz\n",
      "\tUpdating an existing index with 24083 documents loaded from file: buenos-aires_2020-01-23_data_listings.csv.gz\n",
      "\tUpdating an existing index with 24113 documents loaded from file: buenos-aires_2020-02-27_data_listings.csv.gz\n",
      "\tUpdating an existing index with 23968 documents loaded from file: buenos-aires_2020-03-19_data_listings.csv.gz\n",
      "\tUpdating an existing index with 23729 documents loaded from file: buenos-aires_2020-04-26_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (61,62,94,95) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 23828 documents loaded from file: buenos-aires_2020-05-25_data_listings.csv.gz\n",
      "\tUpdating an existing index with 24134 documents loaded from file: buenos-aires_2020-06-21_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20373 documents loaded from file: buenos-aires_2020-10-26_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20545 documents loaded from file: buenos-aires_2020-11-27_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20636 documents loaded from file: buenos-aires_2020-12-24_data_listings.csv.gz\n",
      "\tCreating a new index with 77459 documents loaded from file: london_2019-01-13_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (61,62,94) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 78415 documents loaded from file: london_2019-02-05_data_listings.csv.gz\n",
      "\tUpdating an existing index with 79129 documents loaded from file: london_2019-03-07_data_listings.csv.gz\n",
      "\tUpdating an existing index with 79671 documents loaded from file: london_2019-04-09_data_listings.csv.gz\n",
      "\tUpdating an existing index with 80767 documents loaded from file: london_2019-05-05_data_listings.csv.gz\n",
      "\tUpdating an existing index with 82029 documents loaded from file: london_2019-06-05_data_listings.csv.gz\n",
      "\tUpdating an existing index with 83850 documents loaded from file: london_2019-07-10_data_listings.csv.gz\n",
      "\tUpdating an existing index with 85918 documents loaded from file: london_2019-08-09_data_listings.csv.gz\n",
      "\tUpdating an existing index with 85273 documents loaded from file: london_2019-09-14_data_listings.csv.gz\n",
      "\tUpdating an existing index with 83887 documents loaded from file: london_2019-10-15_data_listings.csv.gz\n",
      "\tUpdating an existing index with 85068 documents loaded from file: london_2019-11-05_data_listings.csv.gz\n",
      "\tUpdating an existing index with 86469 documents loaded from file: london_2019-12-09_data_listings.csv.gz\n",
      "\tUpdating an existing index with 87235 documents loaded from file: london_2020-01-09_data_listings.csv.gz\n",
      "\tUpdating an existing index with 87571 documents loaded from file: london_2020-02-16_data_listings.csv.gz\n",
      "\tUpdating an existing index with 88129 documents loaded from file: london_2020-03-15_data_listings.csv.gz\n",
      "\tUpdating an existing index with 86358 documents loaded from file: london_2020-04-14_data_listings.csv.gz\n",
      "\tUpdating an existing index with 85207 documents loaded from file: london_2020-05-10_data_listings.csv.gz\n",
      "\tUpdating an existing index with 83711 documents loaded from file: london_2020-06-11_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (57,58,88,92) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 81434 documents loaded from file: london_2020-07-14_data_listings.csv.gz\n",
      "\tUpdating an existing index with 74186 documents loaded from file: london_2020-08-24_data_listings.csv.gz\n",
      "\tUpdating an existing index with 77591 documents loaded from file: london_2020-09-11_data_listings.csv.gz\n",
      "\tUpdating an existing index with 76619 documents loaded from file: london_2020-10-13_data_listings.csv.gz\n",
      "\tUpdating an existing index with 76984 documents loaded from file: london_2020-11-06_data_listings.csv.gz\n",
      "\tUpdating an existing index with 77136 documents loaded from file: london_2020-12-16_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (43,61,62,94) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating a new index with 17229 documents loaded from file: mexico-city_2019-03-15_data_listings.csv.gz\n",
      "\tUpdating an existing index with 17868 documents loaded from file: mexico-city_2019-04-17_data_listings.csv.gz\n",
      "\tUpdating an existing index with 18348 documents loaded from file: mexico-city_2019-05-22_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19030 documents loaded from file: mexico-city_2019-06-24_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19357 documents loaded from file: mexico-city_2019-07-16_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20037 documents loaded from file: mexico-city_2019-08-22_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20273 documents loaded from file: mexico-city_2019-09-24_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20568 documents loaded from file: mexico-city_2019-10-20_data_listings.csv.gz\n",
      "\tUpdating an existing index with 20571 documents loaded from file: mexico-city_2019-11-25_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21157 documents loaded from file: mexico-city_2019-12-26_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21477 documents loaded from file: mexico-city_2020-01-23_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21663 documents loaded from file: mexico-city_2020-02-27_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21811 documents loaded from file: mexico-city_2020-03-19_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21801 documents loaded from file: mexico-city_2020-04-23_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21662 documents loaded from file: mexico-city_2020-05-24_data_listings.csv.gz\n",
      "\tUpdating an existing index with 21824 documents loaded from file: mexico-city_2020-06-20_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19180 documents loaded from file: mexico-city_2020-10-26_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19492 documents loaded from file: mexico-city_2020-11-27_data_listings.csv.gz\n",
      "\tUpdating an existing index with 19852 documents loaded from file: mexico-city_2020-12-23_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (43,61,62,94,95) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating a new index with 50717 documents loaded from file: new-york-city_2019-01-09_data_listings.csv.gz\n",
      "\tUpdating an existing index with 50228 documents loaded from file: new-york-city_2019-02-01_data_listings.csv.gz\n",
      "\tUpdating an existing index with 49748 documents loaded from file: new-york-city_2019-03-06_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (43,94,95) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 49466 documents loaded from file: new-york-city_2019-04-03_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (43,95) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 48941 documents loaded from file: new-york-city_2019-05-03_data_listings.csv.gz\n",
      "\tUpdating an existing index with 48801 documents loaded from file: new-york-city_2019-06-02_data_listings.csv.gz\n",
      "\tUpdating an existing index with 48895 documents loaded from file: new-york-city_2019-07-08_data_listings.csv.gz\n",
      "\tUpdating an existing index with 48864 documents loaded from file: new-york-city_2019-08-06_data_listings.csv.gz\n",
      "\tUpdating an existing index with 48377 documents loaded from file: new-york-city_2019-09-12_data_listings.csv.gz\n",
      "\tUpdating an existing index with 48602 documents loaded from file: new-york-city_2019-10-14_data_listings.csv.gz\n",
      "\tUpdating an existing index with 49281 documents loaded from file: new-york-city_2019-11-01_data_listings.csv.gz\n",
      "\tUpdating an existing index with 50599 documents loaded from file: new-york-city_2019-12-04_data_listings.csv.gz\n",
      "\tUpdating an existing index with 51361 documents loaded from file: new-york-city_2020-01-03_data_listings.csv.gz\n",
      "\tUpdating an existing index with 51097 documents loaded from file: new-york-city_2020-02-12_data_listings.csv.gz\n",
      "\tUpdating an existing index with 50796 documents loaded from file: new-york-city_2020-03-13_data_listings.csv.gz\n",
      "\tUpdating an existing index with 50378 documents loaded from file: new-york-city_2020-04-08_data_listings.csv.gz\n",
      "\tUpdating an existing index with 50246 documents loaded from file: new-york-city_2020-05-06_data_listings.csv.gz\n",
      "\tUpdating an existing index with 49530 documents loaded from file: new-york-city_2020-06-08_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.440s]\n",
      "POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.303s]\n",
      "POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.267s]\n",
      "POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.286s]\n",
      "ERROR:root:exception occured\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-bcfd4207c6b0>\", line 98, in ingest_data\n",
      "    app_search.index_documents(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_app_search.py\", line 573, in index_documents\n",
      "    return self.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_base.py\", line 187, in perform_request\n",
      "    return self.transport.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/transport.py\", line 311, in perform_request\n",
      "    resp_status, resp_headers, data = connection.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/http_urllib3.py\", line 251, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/base.py\", line 192, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status, APIError)(\n",
      "elastic_transport.exceptions.ServiceUnavailableError: [503] {'errors': ['The service is in read-only mode. Actions that create, update, or delete information are temporarily disabled.']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 48588 documents loaded from file: new-york-city_2020-07-07_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.223s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.220s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.209s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.251s]\n",
      "ERROR:root:exception occured\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-bcfd4207c6b0>\", line 98, in ingest_data\n",
      "    app_search.index_documents(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_app_search.py\", line 573, in index_documents\n",
      "    return self.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_base.py\", line 187, in perform_request\n",
      "    return self.transport.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/transport.py\", line 311, in perform_request\n",
      "    resp_status, resp_headers, data = connection.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/http_urllib3.py\", line 251, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/base.py\", line 192, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status, APIError)(\n",
      "elastic_transport.exceptions.ServiceUnavailableError: [503] {'errors': ['The service is in read-only mode. Actions that create, update, or delete information are temporarily disabled.']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 46527 documents loaded from file: new-york-city_2020-08-15_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.223s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.241s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.227s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.214s]\n",
      "ERROR:root:exception occured\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-bcfd4207c6b0>\", line 98, in ingest_data\n",
      "    app_search.index_documents(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_app_search.py\", line 573, in index_documents\n",
      "    return self.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_base.py\", line 187, in perform_request\n",
      "    return self.transport.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/transport.py\", line 311, in perform_request\n",
      "    resp_status, resp_headers, data = connection.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/http_urllib3.py\", line 251, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/base.py\", line 192, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status, APIError)(\n",
      "elastic_transport.exceptions.ServiceUnavailableError: [503] {'errors': ['The service is in read-only mode. Actions that create, update, or delete information are temporarily disabled.']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 45756 documents loaded from file: new-york-city_2020-09-07_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.256s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.219s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.216s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.218s]\n",
      "ERROR:root:exception occured\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-bcfd4207c6b0>\", line 98, in ingest_data\n",
      "    app_search.index_documents(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_app_search.py\", line 573, in index_documents\n",
      "    return self.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_base.py\", line 187, in perform_request\n",
      "    return self.transport.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/transport.py\", line 311, in perform_request\n",
      "    resp_status, resp_headers, data = connection.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/http_urllib3.py\", line 251, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/base.py\", line 192, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status, APIError)(\n",
      "elastic_transport.exceptions.ServiceUnavailableError: [503] {'errors': ['The service is in read-only mode. Actions that create, update, or delete information are temporarily disabled.']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 44666 documents loaded from file: new-york-city_2020-10-05_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.234s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.238s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.227s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.235s]\n",
      "ERROR:root:exception occured\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-bcfd4207c6b0>\", line 98, in ingest_data\n",
      "    app_search.index_documents(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_app_search.py\", line 573, in index_documents\n",
      "    return self.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_base.py\", line 187, in perform_request\n",
      "    return self.transport.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/transport.py\", line 311, in perform_request\n",
      "    resp_status, resp_headers, data = connection.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/http_urllib3.py\", line 251, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/base.py\", line 192, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status, APIError)(\n",
      "elastic_transport.exceptions.ServiceUnavailableError: [503] {'errors': ['The service is in read-only mode. Actions that create, update, or delete information are temporarily disabled.']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 44497 documents loaded from file: new-york-city_2020-11-02_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.205s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.202s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.206s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.213s]\n",
      "ERROR:root:exception occured\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-bcfd4207c6b0>\", line 98, in ingest_data\n",
      "    app_search.index_documents(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_app_search.py\", line 573, in index_documents\n",
      "    return self.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_base.py\", line 187, in perform_request\n",
      "    return self.transport.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/transport.py\", line 311, in perform_request\n",
      "    resp_status, resp_headers, data = connection.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/http_urllib3.py\", line 251, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/base.py\", line 192, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status, APIError)(\n",
      "elastic_transport.exceptions.ServiceUnavailableError: [503] {'errors': ['The service is in read-only mode. Actions that create, update, or delete information are temporarily disabled.']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating an existing index with 36923 documents loaded from file: new-york-city_2020-12-10_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.224s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.219s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.229s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines/airbnb-history-new-york-city/documents [status:503 request:0.211s]\n",
      "ERROR:root:exception occured\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-bcfd4207c6b0>\", line 98, in ingest_data\n",
      "    app_search.index_documents(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_app_search.py\", line 573, in index_documents\n",
      "    return self.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_base.py\", line 187, in perform_request\n",
      "    return self.transport.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/transport.py\", line 311, in perform_request\n",
      "    resp_status, resp_headers, data = connection.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/http_urllib3.py\", line 251, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/base.py\", line 192, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status, APIError)(\n",
      "elastic_transport.exceptions.ServiceUnavailableError: [503] {'errors': ['The service is in read-only mode. Actions that create, update, or delete information are temporarily disabled.']}\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines?name=airbnb-history-paris&language=en [status:503 request:0.059s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines?name=airbnb-history-paris&language=en [status:503 request:0.057s]\n",
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines?name=airbnb-history-paris&language=en [status:503 request:0.053s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating a new index with 58359 documents loaded from file: paris_2019-01-13_data_listings.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:elastic_transport.connection:POST http://localhost:3002/api/as/v1/engines?name=airbnb-history-paris&language=en [status:503 request:0.071s]\n",
      "ERROR:root:exception occured\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-6-d30978d9b4a3>\", line 48, in <module>\n",
      "    resp = app_search.create_engine(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_app_search.py\", line 733, in create_engine\n",
      "    return self.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_enterprise_search/client/_base.py\", line 187, in perform_request\n",
      "    return self.transport.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/transport.py\", line 311, in perform_request\n",
      "    resp_status, resp_headers, data = connection.perform_request(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/http_urllib3.py\", line 251, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"/Users/nattiya/miniconda3/envs/dl/lib/python3.8/site-packages/elastic_transport/connection/base.py\", line 192, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status, APIError)(\n",
      "elastic_transport.exceptions.ServiceUnavailableError: [503] {'errors': ['The service is in read-only mode. Actions that create, update, or delete information are temporarily disabled.']}\n"
     ]
    }
   ],
   "source": [
    "# Index listing documents crawled between 2019 - 2020\n",
    "try:\n",
    "    unique_list = [] \n",
    "\n",
    "    print(\"Start indexing ...\")\n",
    "    path = '/Users/nattiya/Desktop/WayBack_InsideAirBNB/'\n",
    "\n",
    "    for file in sorted(os.listdir(path)):\n",
    "        \n",
    "        # Top 10 cities by active listings (https://www.alltherooms.com/analytics/airbnb-statistics/):\n",
    "        if (file.startswith(\"london\") or file.startswith(\"paris\") or file.startswith(\"new-york-city\") or file.startswith(\"rome\") or file.startswith(\"rio-de-janeiro\") or file.startswith(\"buenos-aires\") or file.startswith(\"sydney\") or file.startswith(\"mexico-city\") or file.startswith(\"barcelona\")) and ((\"2019-\" in file) or (\"2020-\" in file)) and file.endswith(\".csv.gz\"):\n",
    "            \n",
    "            # Extract city name from file\n",
    "            name = file.find(\"_\")\n",
    "            city = file[0:name].lower()\n",
    "\n",
    "            # Load original listing data\n",
    "            df = pd.read_csv(path + file, compression='gzip')\n",
    "\n",
    "            # Pre-process raw data\n",
    "            # Step 1: Enrich raw data with price and crawled date\n",
    "            df = validate_price(df)\n",
    "            df = get_crawled_date(df)\n",
    "            df = gen_missing_columns(df)\n",
    "            raw_count = len(df)\n",
    "\n",
    "            # Step 2: Assign ratings to listings with no reviews\n",
    "            df = get_features(df)\n",
    "            df = validate_reviews(df)\n",
    "            review_count = len(df)\n",
    "\n",
    "            # Step 3: Drop records with null values\n",
    "            #df = drop_null_values(df)\n",
    "            df = fill_null_values(df)\n",
    "            final_count = len(df)\n",
    "\n",
    "            # Obtain the index name\n",
    "            index_name = 'airbnb-history-' + city\n",
    "\n",
    "            # Check if the city is seen for the first time \n",
    "            if index_name not in unique_list:\n",
    "\n",
    "                print(\"\\tCreating a new index with %d documents loaded from file: %s\" % (final_count, file))\n",
    "\n",
    "                unique_list.append(index_name)\n",
    "\n",
    "                # Initialize index (only perform once)\n",
    "                resp = app_search.create_engine(\n",
    "                    engine_name=index_name,\n",
    "                    language=\"en\"\n",
    "                )\n",
    "                \n",
    "                # Index documents loaded from the current snapshot\n",
    "                ingest_data(df, index=index_name, total_docs=final_count)\n",
    "                \n",
    "                # Updating schema\n",
    "                resp = app_search.put_schema(\n",
    "                    engine_name=index_name,\n",
    "                    schema={\n",
    "                      \"accommodates\": \"number\",\n",
    "                      \"availability_30\": \"number\",\n",
    "                      \"availability_365\": \"number\",\n",
    "                      \"availability_60\": \"number\",\n",
    "                      \"availability_90\": \"number\",\n",
    "                      \"guests_included\": \"number\",\n",
    "                      \"maximum_nights\": \"number\",\n",
    "                      \"minimum_nights\": \"number\",\n",
    "                      \"number_of_reviews\": \"number\",\n",
    "                      \"overall_rating\": \"number\",\n",
    "                      \"price\": \"number\",\n",
    "                      \"review_scores_accuracy\": \"number\",\n",
    "                      \"review_scores_checkin\": \"number\",\n",
    "                      \"review_scores_cleanliness\": \"number\",\n",
    "                      \"review_scores_communication\": \"number\",\n",
    "                      \"review_scores_location\": \"number\",\n",
    "                      \"review_scores_rating\": \"number\",\n",
    "                      \"review_scores_value\": \"number\",\n",
    "                      \"calendar_updated\": \"text\",\n",
    "                      \"cancellation_policy\": \"text\",\n",
    "                      \"crawled_date\": \"text\",\n",
    "                      \"first_review\": \"text\",\n",
    "                      \"host_id\": \"text\",\n",
    "                      \"host_identity_verified\": \"text\",\n",
    "                      \"host_is_superhost\": \"text\",\n",
    "                      \"instant_bookable\": \"text\",\n",
    "                      \"is_business_travel_ready\": \"text\",\n",
    "                      \"last_review\": \"text\",\n",
    "                      \"last_scraped\": \"text\",\n",
    "                      \"listing_url\": \"text\",\n",
    "                      \"name\": \"text\",\n",
    "                      \"room_type\": \"text\",\n",
    "                      \"scrape_id\": \"t\n",
    "                        ext\"\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"\\tUpdating an existing index with %d documents loaded from file: %s\" % (final_count, file))\n",
    "                \n",
    "                ingest_data(df, index=index_name, total_docs=final_count)\n",
    "                \n",
    "    print(\"Finished indexing ...\")\n",
    "\n",
    "except Exception:\n",
    "    logging.error('exception occured', exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
